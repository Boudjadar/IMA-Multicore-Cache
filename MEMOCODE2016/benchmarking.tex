\label{sec:methodology}
Throughout this section we describe how the inputs required by our model-based framework are obtained form an actual system, in particular WCETs and WCRAs. In software engineering, benchmarking \cite{Benchmarking} aims at measuring a set of execution attributes and performance characteristics, e.g. WCET, of a given software system. %The user has to run the application to be benchmarked on the target platform to determine for example the execution time of each process. 
The output of a system benchmarking (shortly known by benchmark) will be used to reconstruct a behavioral model of the system,  which can be used in turn for simulation and analysis purposes. Benchmarking is known as an expensive operation that involves several iterative rounds in order to reach conclusive decisions. %In this context, we are interested in how WCET and WCRA are derived from a concrete multicore software system. 
Roughly speaking, flow analysis and profiling are the most commonly used techniques to measure the WCET and WCRA of application tasks.  

Flow analysis \cite{Tan2009,Chatto2012} is a technique to estimate the WCET of a program. It consists of simulating, or concretely running, a program in isolation and measuring the time spent. Technically, static analysis tools use symbolic execution engines to identify potential execution paths without necessarily having to run the program. Such representations can be structured in terms of control flow graph (CFG). %Similarly to compilers, a static analysis tool parses a source code of a program and converts it to an intermediate representation where each state could be a class of different program configurations. 
WCET is then the time spent when executing the longest path of the CFG. Static analysis has been practiced for the analysis of software systems via different analysis tools, e.g. {SWEET} \cite{Tan2009}. 
%The depth of the model determines the effectiveness of the tool. That depth is based on how much knowledge of program behaviour is built in, how much of the program it can take into account at once and how accurately it reflects actual program behaviour. 

%Conventionally, task periods and deadlines (potentially also priority and criticality levels) are identifiable during the requirements analysis.

System profiling \cite{Yun2012,Kim14} is a measurement-based approach to estimate how many times a process accesses  shared memories. The system being analyzed is run for a sufficient number of times, each of which for a long enough duration enabling the execution of most of the system functions (code). The analysis focuses on each process individually, so that for each run we track how many times a process accesses a given shared memory. However, due to technology limitations, the measurements can be performed at core level only, so that the obtained access number of a given core corresponds to the set of processes running on top of it. In order to obtain the memory access number for each process, one needs to run each process individually on one core during the analysis, so that the access number obtained corresponds to the process being run. The number of accesses for each core can be obtained using Performance Monitor Counters (PMCs) \cite{Yun2012}, equipping certain multicore platforms. %Such a number is commonly called \textit{Worst Case Resource Access} (WCRA) \cite{Nowotsch14}. 

In literature \cite{Kim14,Yun2012}, profiling and static analysis techniques are not completely differentiated. Both techniques can be used to measure WCET and WCRA.
  

%Once the attributes of system tasks are determined, one can apply rigourous schedulability analysis tools suing either analytic approaches \cite{***} or model-based enginnering approaches \cite{***}.   